name: Publish To PyPI

on:
  push:
    tags:
      - 'v*'        # runs only when you push tags like v1.2.3

jobs:
  build-publish:
    runs-on: ubuntu-latest

    steps:
      # 1 – Check out the repo
      - uses: actions/checkout@v2

      # 2 – Expose the tag (e.g. 1.2.3) as $PACKAGE_VERSION
      - name: Set environment package version from tag
        run: echo "PACKAGE_VERSION=${GITHUB_REF#refs/*/v}" >> "$GITHUB_ENV"

      # 3 – Set up Python
      - uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # 4 – Set up Node.js
      - uses: actions/setup-node@v4
        with:
          node-version: '20.x'

      # 5 – Set up JDK 11 (adopt) and enable sbt cache
      - name: Set up JDK 11
        uses: actions/setup-java@v4
        with:
          distribution: 'adopt'
          java-version: '11'
          cache: 'sbt'

      # 6 – Install the sbt launcher
      - name: Set up sbt
        uses: sbt/setup-sbt@v1
        with:
          sbt-runner-version: '1.9.9'

      # 7 – Install Python build & upload deps
      - name: Install Python dependencies
        run: pip install build twine

      # 8 – Build the wheel/sdist
      - name: Build distribution
        run: python -m build

      # 9 – Upload to PyPI
      - name: Publish distribution to PyPI
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
        run: twine upload --repository pypi dist/*

      # 10 – Trigger downstream workflow
      - name: Invoke workflow in systemuser-image
        uses: benc-uk/workflow-dispatch@v1
        with:
          workflow: SWAN CI/CD pipeline
          ref: master
          repo: swan-cern/systemuser-image
          token: ${{ secrets.WORKFLOW_ACCESS_TOKEN }}
          inputs: |
            {
              "package": "sparkmonitor",
              "version": "${{ env.PACKAGE_VERSION }}"
            }

